[
  {
    "objectID": "writing/index.html",
    "href": "writing/index.html",
    "title": "Writing",
    "section": "",
    "text": "Magical Skills\n\n\n\n\n\n\nskill acquistion\n\n\nteam performance\n\n\n\nWhat if we rethink the limits of skills we don’t really think much about?\n\n\n\n\n\n13 Apr 2024\n\n\nAlex Leeds\n\n\n\n\n\n\nNo matching items\n\nCitationBibTeX citation:@misc{leeds,\n  author = {Alex Leeds},\n  title = {Writing},\n  url = {https://alexleeds.com/writing},\n  langid = {en-GB}\n}\nFor attribution, please cite this work as:\nAlex Leeds. n.d. “Writing.” https://alexleeds.com/writing."
  },
  {
    "objectID": "alexleeds.github.io-env/lib/python3.12/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html",
    "href": "alexleeds.github.io-env/lib/python3.12/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html",
    "title": "Alex Leeds",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "alexleeds.github.io-env/lib/python3.12/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html#authors",
    "href": "alexleeds.github.io-env/lib/python3.12/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html#authors",
    "title": "Alex Leeds",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Alex Leeds",
    "section": "",
    "text": "I’m a data scientist who predicts (and sometimes designs) consumer behavior. I use a mix of experiments, human feedback, and computationally intensive methods to refine ads, pricing, monetization, market segmentation, and product/feature selection.\nUntil April 2024, I was the CEO and Co-founder of Sleuth. Sleuth was an app and website that provided running feedback to parents about their kids’ development using machine learning-based benchmarks for 250 topics. We had more than 60,000 parents contribute answers to 1.25 million questions between 2022 and 2023.\nBefore Sleuth, I managed data science teams at Squarespace and One Zero Capital and was a Data Scientist in Residence at IDEO. I have a BA from Yale University in Political Science and a PhD in a mix of economics, statistics, and applied psychology from Wharton Business School."
  },
  {
    "objectID": "index.html#hello-and-welcome",
    "href": "index.html#hello-and-welcome",
    "title": "Alex Leeds",
    "section": "",
    "text": "I’m a data scientist who predicts (and sometimes designs) consumer behavior. I use a mix of experiments, human feedback, and computationally intensive methods to refine ads, pricing, monetization, market segmentation, and product/feature selection.\nUntil April 2024, I was the CEO and Co-founder of Sleuth. Sleuth was an app and website that provided running feedback to parents about their kids’ development using machine learning-based benchmarks for 250 topics. We had more than 60,000 parents contribute answers to 1.25 million questions between 2022 and 2023.\nBefore Sleuth, I managed data science teams at Squarespace and One Zero Capital and was a Data Scientist in Residence at IDEO. I have a BA from Yale University in Political Science and a PhD in a mix of economics, statistics, and applied psychology from Wharton Business School."
  },
  {
    "objectID": "index.html#personal-life",
    "href": "index.html#personal-life",
    "title": "Alex Leeds",
    "section": "Personal life",
    "text": "Personal life\nI live in New York City on the Upper East Side with my wife, daughter, and two vocal cats.\nIn my free time, I enjoy reading biographies, swimming (badly), and coding projects for pure entertainment. I also created and (lightly) oversee a meetup called NYC AI Hackers that runs events exploring data science and AI applications.\nGet in touch by sending me a note."
  },
  {
    "objectID": "projects/some-fun-projects/index.html",
    "href": "projects/some-fun-projects/index.html",
    "title": "Some Fun Projects",
    "section": "",
    "text": "These are a handful of toy projects that I’m working on in the next 12 months. This is a brand new website, so I’ll gradually post more content as I get around to it. Most of these projects use some form of AI because there is just so much opportunity for exciting work using AI methods and tools.\n\nA universal lexicon\nWhat useful, fun, or interesting words exist in other languages but not in English?\nSince the dawn of the Internet, people have published lists of words like this.\nWe think in language, and so our vocabulary literally creates a bound on our ideas. I don’t have a strong desire to learn other languages right now, but I’m enthusiastic to expand the universe of words I have for concepts.\nOne approach for finding these words is to get a bunch of fluent speakers in non-English languages together and to ask them what is missing in English. But this is difficult to make comprehensive without a large time commitment by others or a large working group.\nNow, LLMs have produced a beautiful solution to this problem through text embeddings. We can simply find words and phrases in other languages that are “distant” from English words in certain relevant dimensions and forms. It’s tricky to locate the patterns that identify useful and interesting words but very doable.\nOnce we have relevant lists, I think there are a bunch of other minor challenges:\n\nProvide definitions, some appropriate grammar (for an English speaker), and examples to make this practically useful\nOrganize the words - likely as in a thesaurus\nAs with all of these projects, open it up for others to contribute!\n\n\n\nAI debates\n\n\n\nDebate visual under development.\n\n\n\nI recently hosted a live, in-person, spoken debate between OpenAI’s GPT-4 Turbo and Google’s Gemini Pro on the topic: “Standardized testing should be abolished.”\nOpenAI was randomly assigned the affirmative position and Gemini was assigned the negative position. The debate had the following format.\n\nOpening Statements (2 minutes each)\nArguments (3 minutes)\nRebuttal (3 minutes)\nConclusion (2 minutes)\n\nAfter the debate, the audience and the AIs judged the winner.\nTechnically, these debates have three technical problems - all of them quite interesting: (1) How do we improve the responses AIs provide? For instance, they can search Internet references or use RAGs to retrieve the right material for a line of argument. (2) How do we turn AI responses into spoken audio? (text-to-speech) (3) How do we visualize the debate audio?\nMy current implementation of these is extremely rough - just enough to run a debate that people truly enjoyed.\n\n\nTrends in aesthetics\nWe love things that are slightly different in style from products we already know. This influences our preferences in every art form: clothing, music, food, software, etc.\nThe corollary is also true: We dislike things that are too different.\nThis influences our preferences in every art form: clothing, music, food, software, etc.\nIf you want to create something that people will love - aesthetically - you usually have three options:\n\nReversion: You can bring back a familiar style that is no longer current. This leads to well-known loops in aesthetics that often swing backward by ~20 to 30 years.\nCombination: You can take aesthetics that people already appreciate in one sphere and apply them to another. Styles in clothing might be extended to rugs, upholstery, etc.\nIncremental Progress: We can slowly push the limits of preferences for speed or volume.\n\nThe fascinating thing about incremental trends in aesthetics, is that you might be able to see where they are going without being able to jump ahead to wherever they will be. People have to gradually adjust their preferences.\nThe frequency of cuts in movies will get faster or slower. Songs will get louder or quieter. Foods in some cuisines might get spicier. But audiences today are not ready for the preference that will follow 10 years from now. If someone made a song in the 1980s that was as loud as the current “loud” songs, no one would have liked them.\nI wonder if we can find examples. How about…\nFrequency of cuts in moving making? Number of spoken words/minute in songs? Loudness of songs? Preferences of spiciness in certain cuisines?\nMy first project in this space, however, is to look at trends in color palettes in commercial clothing. I’m capturing images of clothes from hundreds of design clothing companies’ archived websites and using neural nets to explore broad patterns in the clothings’ color schemes.\n\n\nGeneral purpose AI chess\nSince IBM Deep Blue in the 1980s (and, of course, earlier), chess has been a fun proving ground for computer problem solving.\nI like testing the ability of generalist AI programs from Google, OpenAI, Anthropic, etc. to play chess because it isn’t something that naturally follows from the “provide the best next text” emphasis that was used to train these chat systems. They surely pick up chess data during training, but playing chess well is still a pretty specialized problem. It requires a demanding mix of memory, tactical, and strategic solutions that we think of as a distinct domain expertise.\nThe other great thing about chess is that we have incredibly strong chess engines like Stockfish that can be set for varying difficulty levels to allow us to test exactly how strong the AI programs currently are.\nI’ve tested how well OpenAI performs at chess against Stockfish. Over time, I want to track the improvements in AI performance, pit them against each other, and explore these AIs’ abilities to reason about their own chess moves."
  },
  {
    "objectID": "disclaimer/index.html",
    "href": "disclaimer/index.html",
    "title": "Alex Leeds",
    "section": "",
    "text": "Opinions expressed on this Site are the author’s own in his personal capacity. They do not reflect the views of the United States Government, the Hello Sleuth Inc. or of any organisation, company or board he is associated with."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Some Fun Projects\n\n\n\n\n\n\nUniversal lexicon\n\n\nAI debates\n\n\nAI chess\n\n\nAethetic trends\n\n\n\nStuff I’m excited about \n\n\n\n\n\nApr 16, 2024\n\n\nAlex Leeds\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "alexleeds.github.io-env/lib/python3.12/site-packages/numpy/random/LICENSE.html",
    "href": "alexleeds.github.io-env/lib/python3.12/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "alexleeds.github.io-env/lib/python3.12/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "alexleeds.github.io-env/lib/python3.12/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "UAT for NbAgg backend.",
    "section": "",
    "text": "from imp import reload"
  },
  {
    "objectID": "alexleeds.github.io-env/lib/python3.12/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "href": "alexleeds.github.io-env/lib/python3.12/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "title": "UAT for NbAgg backend.",
    "section": "UAT for NbAgg backend.",
    "text": "UAT for NbAgg backend.\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\n\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)\n\n\nUAT 1 - Simple figure creation using pyplot\nShould produce a figure window which is interactive with the pan and zoom buttons. (Do not press the close button, but any others may be used).\n\nimport matplotlib.backends.backend_webagg_core\nreload(matplotlib.backends.backend_webagg_core)\n\nimport matplotlib.pyplot as plt\nplt.interactive(False)\n\nfig1 = plt.figure()\nplt.plot(range(10))\n\nplt.show()\n\n\n\nUAT 2 - Creation of another figure, without the need to do plt.figure.\nAs above, a new figure should be created.\n\nplt.plot([3, 2, 1])\nplt.show()\n\n\n\nUAT 3 - Connection info\nThe printout should show that there are two figures which have active CommSockets, and no figures pending show.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 4 - Closing figures\nClosing a specific figure instance should turn the figure into a plain image - the UI should have been removed. In this case, scroll back to the first figure and assert this is the case.\n\nplt.close(fig1)\nplt.close('all')\n\n\n\nUAT 5 - No show without plt.show in non-interactive mode\nSimply doing a plt.plot should not show a new figure, nor indeed update an existing one (easily verified in UAT 6). The output should simply be a list of Line2D instances.\n\nplt.plot(range(10))\n\n\n\nUAT 6 - Connection information\nWe just created a new figure, but didn’t show it. Connection info should no longer have “Figure 1” (as we closed it in UAT 4) and should have figure 2 and 3, with Figure 3 without any connections. There should be 1 figure pending.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 7 - Show of previously created figure\nWe should be able to show a figure we’ve previously created. The following should produce two figure windows.\n\nplt.show()\nplt.figure()\nplt.plot(range(5))\nplt.show()\n\n\n\nUAT 8 - Interactive mode\nIn interactive mode, creating a line should result in a figure being shown.\n\nplt.interactive(True)\nplt.figure()\nplt.plot([3, 2, 1])\n\nSubsequent lines should be added to the existing figure, rather than creating a new one.\n\nplt.plot(range(3))\n\nCalling connection_info in interactive mode should not show any pending figures.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\nDisable interactive mode again.\n\nplt.interactive(False)\n\n\n\nUAT 9 - Multiple shows\nUnlike most of the other matplotlib backends, we may want to see a figure multiple times (with or without synchronisation between the views, though the former is not yet implemented). Assert that plt.gcf().canvas.manager.reshow() results in another figure window which is synchronised upon pan & zoom.\n\nplt.gcf().canvas.manager.reshow()\n\n\n\nUAT 10 - Saving notebook\nSaving the notebook (with CTRL+S or File-&gt;Save) should result in the saved notebook having static versions of the figures embedded within. The image should be the last update from user interaction and interactive plotting. (check by converting with ipython nbconvert &lt;notebook&gt;)\n\n\nUAT 11 - Creation of a new figure on second show\nCreate a figure, show it, then create a new axes and show it. The result should be a new figure.\nBUG: Sometimes this doesn’t work - not sure why (@pelson).\n\nfig = plt.figure()\nplt.axes()\nplt.show()\n\nplt.plot([1, 2, 3])\nplt.show()\n\n\n\nUAT 12 - OO interface\nShould produce a new figure and plot it.\n\nfrom matplotlib.backends.backend_nbagg import new_figure_manager,show\n\nmanager = new_figure_manager(1000)\nfig = manager.canvas.figure\nax = fig.add_subplot(1,1,1)\nax.plot([1,2,3])\nfig.show()"
  },
  {
    "objectID": "alexleeds.github.io-env/lib/python3.12/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "alexleeds.github.io-env/lib/python3.12/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "UAT for NbAgg backend.",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "writing/magical-skills/index.html",
    "href": "writing/magical-skills/index.html",
    "title": "Magical Skills",
    "section": "",
    "text": "Barbara Corcoran, founder of the Corcoran (real estate) Group, recently tweeted, “The hardest lesson to learn is that you are more capable than you think you are.”\nI’ve often wondered about this: how do we hem ourselves in by our own expectations?\nAt a simplistic level, tons of research on implicit beliefs, growth mindset, and underachievement explores the basic idea: If we believe we can’t learn or do something - or just that our skills in some domain are inherited rather than acquired - then we don’t learn it.\nBut I’m interested in another layer of this problem: opportunities we miss because almost no one believes that a skill is possible for any individual or group. What about the limits we impose from lack of imagination rather than from lack of self-confidence?"
  },
  {
    "objectID": "writing/magical-skills/index.html#what-impossible-skills-are-actually-possible",
    "href": "writing/magical-skills/index.html#what-impossible-skills-are-actually-possible",
    "title": "Magical Skills",
    "section": "What “impossible” skills are actually possible?",
    "text": "What “impossible” skills are actually possible?\nWhat if we lived in a world where long distance running had never been invented as a sport? Would we believe that a human could run 26 miles in under 4:36 seconds per mile? Probably not.\nWhat if we lived in a world where professional musicians didn’t exist, and then imported Yuja Wang? Her performance would seem like magic: the memory of those hundreds of thousands of notes delivered with impossible control.\nBut there are abilities that most people would probably not imagine at all.\n\nWe can hold our breath for more than 20 minutes (Wired article and Scientific American).\nWe can perfectly recall 500 single-digit numbers having heard them listed only once.\nApollo Robbins can remove your watch without your awareness even when you are trying to prevent him.\n\nThe most extreme examples are due to rare talent as well as extreme effort. But a fraction of these performances is still outside the usual range of “believable.”\nCould we do the same with slightly more practical skills? Paul Ekman made a science out of reading people’s emotions (Emotions Revealed), for example. What could we do if we imagined other useful skills.\nImagine if we collected thousands of video clips from YouTube of just people…\n\nintroducing themselves\nmaking persuasive arguments\ninterrupting other people\ndefending a belief\nmaking jokes classified by style\n\nHow are these done well? When do they fail? This is now a feasible AI project."
  },
  {
    "objectID": "writing/magical-skills/index.html#what-could-groups-do",
    "href": "writing/magical-skills/index.html#what-could-groups-do",
    "title": "Magical Skills",
    "section": "What could groups do?",
    "text": "What could groups do?\nAnd what about groups? Most of our models for how people behave in social and work settings are based on limited scenarios and narrow comfort levels.\nWhat if we took the hours, focus, and energy of a five-star restaurant kitchen staff and expected Facebook software developers to perform similarly? I think some of them might actually die from exhaustion before the week was over.\nCould we change how people think about working as a team in professional settings? What if we really did cross software development with the skills/practical elements of other fields like restaurants, or sports, or concert music? What if we also tailored the workflows of different teams to more accurately reflect the kinds of outcomes t hey aim to produce?\nJensen Huang recently made this argument. He criticized engineering firms for adopting a generic pattern for organizational structure and functions. Similarly, I still see hospitals fighting (and failing) to overcome the departmental structure that has existed for decades. And many private equity firms still use approaches that Siegmund Warburg designed in the 1940s and 1950s.\nOur expectations for ourselves, for our professions, and for our societies are hide-bound. I’m not sure what to do about it, but I’m certain that we set our sights far too low."
  }
]